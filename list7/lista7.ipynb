{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "embedding_dim = 50\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# x_train = pad_sequences(train_data, maxlen=100)\n",
    "# x_test = pad_sequences(test_data, maxlen=100)\n",
    "\n",
    "# y_train = torch.Tensor(train_labels)\n",
    "# y_test = torch.Tensor(test_labels)\n",
    "\n",
    "# x_train_np = np.array(x_train)\n",
    "# y_train_np = np.array(y_train)\n",
    "# x_test_np = np.array(x_test)\n",
    "# y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_RNN(recurrent_units):\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=100))\n",
    "    model_rnn.add(SimpleRNN(units=recurrent_units))\n",
    "    model_rnn.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model_rnn.fit(x_train_np, y_train_np, epochs=num_epochs, batch_size=32, validation_data=(x_test_np, y_test_np), verbose=0)\n",
    "\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_LSTM(recurrent_units):\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=100))\n",
    "    model_lstm.add(LSTM(units=recurrent_units))\n",
    "    model_lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model_lstm.fit(x_train_np, y_train_np, epochs=num_epochs, batch_size=32, validation_data=(x_test_np, y_test_np), verbose=0)\n",
    "    return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, model_name, recurrent_units, max_sequence_length):\n",
    "    y_pred = model.predict(x_test_np, verbose=0)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(f\"Model: {model_name}; Recurrent Units: {recurrent_units}; max_sequence_length: {max_sequence_length}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test_np, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test_np, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_test_np, y_pred)}\")\n",
    "    print(f\"F1-score: {f1_score(y_test_np, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_units_to_test = [16, 64, 128]\n",
    "max_sequence_lengths = [1, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 16; max_sequence_length: 1\n",
      "Accuracy: 0.59744\n",
      "Precision: 0.5829361296472831\n",
      "Recall: 0.68488\n",
      "F1-score: 0.6298094607518576\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 16; max_sequence_length: 1\n",
      "Accuracy: 0.59672\n",
      "Precision: 0.5974057363841444\n",
      "Recall: 0.5932\n",
      "F1-score: 0.5952954399486191\n",
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 16; max_sequence_length: 100\n",
      "Accuracy: 0.81976\n",
      "Precision: 0.8054409292373529\n",
      "Recall: 0.8432\n",
      "F1-score: 0.8238880637848824\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 16; max_sequence_length: 100\n",
      "Accuracy: 0.83612\n",
      "Precision: 0.8164494991338405\n",
      "Recall: 0.8672\n",
      "F1-score: 0.8410598595647282\n",
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 64; max_sequence_length: 1\n",
      "Accuracy: 0.59364\n",
      "Precision: 0.5835772938236344\n",
      "Recall: 0.65384\n",
      "F1-score: 0.6167138275797018\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 64; max_sequence_length: 1\n",
      "Accuracy: 0.59604\n",
      "Precision: 0.6063990073561996\n",
      "Recall: 0.54736\n",
      "F1-score: 0.5753689610225791\n",
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 64; max_sequence_length: 100\n",
      "Accuracy: 0.79136\n",
      "Precision: 0.7866362348496773\n",
      "Recall: 0.7996\n",
      "F1-score: 0.7930651432198682\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 64; max_sequence_length: 100\n",
      "Accuracy: 0.8352\n",
      "Precision: 0.8305459135373935\n",
      "Recall: 0.84224\n",
      "F1-score: 0.8363520813473149\n",
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 128; max_sequence_length: 1\n",
      "Accuracy: 0.59388\n",
      "Precision: 0.5755877616747181\n",
      "Recall: 0.71488\n",
      "F1-score: 0.6377163247100802\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 128; max_sequence_length: 1\n",
      "Accuracy: 0.59184\n",
      "Precision: 0.585556714860635\n",
      "Recall: 0.62856\n",
      "F1-score: 0.6062967821591173\n",
      "--------------------------------------------------------\n",
      "Model: rnn model; Recurrent Units: 128; max_sequence_length: 100\n",
      "Accuracy: 0.76408\n",
      "Precision: 0.7500757575757576\n",
      "Recall: 0.79208\n",
      "F1-score: 0.7705058365758756\n",
      "--------------------------------------------------------\n",
      "Model: lstm model; Recurrent Units: 128; max_sequence_length: 100\n",
      "Accuracy: 0.83112\n",
      "Precision: 0.8318101651434985\n",
      "Recall: 0.83008\n",
      "F1-score: 0.8309441819492271\n"
     ]
    }
   ],
   "source": [
    "for recurrent_units in recurrent_units_to_test:\n",
    "    for max_sequence_length in max_sequence_lengths:\n",
    "    \n",
    "        (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "        x_train = pad_sequences(train_data, maxlen=max_sequence_length)\n",
    "        x_test = pad_sequences(test_data, maxlen=max_sequence_length)\n",
    "\n",
    "        y_train = torch.tensor(train_labels)\n",
    "        y_test = torch.tensor(test_labels)\n",
    "\n",
    "        x_train_np = np.array(x_train)\n",
    "        y_train_np = np.array(y_train)\n",
    "        x_test_np = np.array(x_test)\n",
    "        y_test_np = np.array(y_test)\n",
    "\n",
    "\n",
    "        model_rnn = compile_RNN(recurrent_units)\n",
    "        model_lstm = compile_LSTM(recurrent_units)\n",
    "        \n",
    "        get_metrics(model_rnn, \"rnn model\", recurrent_units, max_sequence_length)\n",
    "        get_metrics(model_lstm, \"lstm model\", recurrent_units, max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza danych prezentuje wyniki metryk dla modeli rekurencyjnych RNN i LSTM o różnych rozmiarach jednostek rekurencyjnych oraz maksymalnych długości sekwencji.\n",
    "\n",
    "Porównanie modeli RNN i LSTM:\n",
    "Dla krótkich sekwencji, modele LSTM mają tendencję do osiągania lepszych wyników niż modele RNN pod względem wszystkich metryk.\n",
    "Dla długich sekwencji, różnice między modelami RNN a LSTM są bardziej zróżnicowane, ale ogólnie modele LSTM zdają się osiągać lepsze wyniki.\n",
    "\n",
    "Wpływ liczby jednostek rekurencyjnych:\n",
    "Dla obu typów modeli (RNN i LSTM), zwiększenie liczby jednostek rekurencyjnych z 16 do 64 wydaje się poprawiać wyniki dla wszystkich metryk, zwłaszcza dla długich sekwencji.\n",
    "Dla dalszego zwiększenia liczby jednostek rekurencyjnych z 64 do 128, wyniki są zróżnicowane, ale niekoniecznie poprawiają się we wszystkich przypadkach.\n",
    "\n",
    "Wpływ długości sekwencji:\n",
    "Dla obu typów modeli i różnych rozmiarów jednostek rekurencyjnych, zwiększenie maksymalnej długości sekwencji z 1 do 100 powoduje znaczną poprawę wyników we wszystkich metrykach.\n",
    "W przypadku długich sekwencji, modele LSTM często osiągają lepsze wyniki niż modele RNN.\n",
    "\n",
    "Najlepsze wyniki:\n",
    "Najlepsze wyniki zdają się być osiągane przez modele LSTM z 128 jednostkami rekurencyjnymi i długimi sekwencjami.\n",
    "Warto zauważyć, że modele te osiągają wysoką dokładność, precyzję, czułość i F1-score, co sugeruje, że są one skuteczne w rozwiązaniu danego problemu.\n",
    "\n",
    "Wnioski:\n",
    "Modele LSTM jako specjalistyczne modele RNN lepiej radzą sobię z tym zadaniem. \n",
    "Zwiększenie liczby jednostek rekurencyjnych oraz długości sekwencji może poprawić wyniki, ale należy zwrócić uwagę na ewentualne wzrosty złożoności obliczeniowej."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
